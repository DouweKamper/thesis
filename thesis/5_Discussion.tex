\section{Discussion}\label{Discussion}
All three samplers managed to converge to similar posterior distributions for the different models and prior-likelihood combinations, but differences in efficiency were observed. The AI sampler was consistently outperformed by DE and DE-SNK, reporting too high acceptance rates, relatively low $\widehat{ESS}$ and higher $\hat{R}$, making AI overall less efficient. The differences reported between DE and DE-SNK are much smaller, with DE appearing slightly better for Model 1 ($d$=1), but DE-SNK showing superior performance diagnostics for Model 4 ($d$=5). With increasing dimensionality, this difference is expected to increase further in favour of DE-SNK. \cite{terbraak2008differential} showed that DE-SNK outperforms DE for different student distributions with dimensionality ranging from 10 to 100. Furthermore, DE-SNK is a component of the $\text{Multiple-Try DREAM}_{(zs)}$ algorithm, which has been specifically designed to solve high-dimensional posteriors in hydrology \citep{laloy2012high}. For hydrogeological modelling, these results suggest that DE-SNK is the better choice, as models are typically highly parameterized. 

% CONVERGENCE
There was some concern that the second mode in the posteriors of Model 1 was caused by convergence issues, such as chains getting stuck, or the burn-in phase being too short. However, inspection of trace plots revealed that different chains move back and forth between these modes. For example, ensemble 5 from DE with the narrow prior (\hyperref[traceplot_DE_priornarrow]{\textcolor{blue}{Figure }\ref{traceplot_DE_priornarrow}}) and ensemble 1 from DE with the wide prior (\hyperref[traceplot_DE_priorbroad]{\textcolor{blue}{Figure }\ref{traceplot_DE_priorbroad}}).  

Though there are exceptions, where different chains appear stuck in a different mode, not mixing, e.g. ensemble 2 from AI with the narrow prior (\hyperref[traceplot_AI_priornarrow]{\textcolor{blue}{Figure }\ref{traceplot_AI_priornarrow}}). As a consequence $\hat{R}$ for this ensemble is very high (1.44), but also the ensembles containing chains that do move back and forth between modes tend to have a relatively high $\hat{R}$ (e.g. 1.27, \hyperref[traceplot_DE_priornarrow]{\textcolor{blue}{Figure }\ref{traceplot_DE_priornarrow}}), indicating that a chain length of 1000 steps post-burn in was too short to achieve adequate mixing. %for chains to consistently sample both mode.

% PRIOR CHOICE
% which prior is better: informative vs uninformative
% also touch upon gaussian vs uniform
% reflection on own prior selection
Results show that prior choice has a strong impact on the selected performance diagnostics. With the more informative prior, on average, resulting in a more optimal acceptance rate, higher $\widehat{ESS}$, lower $\hat{R}$, and posterior medians closer to the 'true' hydraulic conductivities. In contrast, the convention in hydrogeology is to use uniform prior distributions \citep{laloy2012high, keating2010optimization}. 
Although uniform priors are often chosen for their perceived lack of influence, this assumption is incorrect. In reality, they are weakly informative, assigning equal probability mass to both implausible and plausible values \citep{gelman2020holes}. Given these findings, it is recommended that hydrogeologists carefully reconsider their choice of priors.

Also in this study improvements can be made on prior design. The standard deviation of the narrow prior was too small considering the uncertainty of the parameter estimate. The transformed standard deviation of the parameter equals 0.25 orders of magnitude (\hyperref[tab_priors]{\textcolor{blue}{Table }\ref{tab_priors}}). In contrast, true values approaching 1.0 orders of magnitude away from the centre of the prior distribution are possible, though unlikely, given that $>99.99\%$ of probability density mass is within 4$\sigma$. % actually largest difference in my case is 5.0 m/d !, so this is definitely less of a problem, with the respective sigma being approx 3 
This poses certain risks considering that the posterior predictive distribution can be strongly affected by the prior when there is not much observed data and substantial prior mass is concentrated around infeasible values \citep{gelman2006prior}. A better choice may have been to increase the narrow prior standard deviation from 0.125 to say 0.25 (so still half of the wide prior). This would decrease the amount of prior density concentrated around unfeasible values, when the estimate is relatively far off from the true value. 
% PRIOR NOTES
%The posterior predictive distribution can be strongly affected by the prior when there is not much observed data and substantial prior mass is concentrated around infeasible values \citep{gelman2006prior}. Therefore careful prior selection is very important, pointy is definitely risky (e.g. Model1). Also consider assigning less weight to prior?
% prior design is not exactly perfect. Informative prior should have larger std with respect to uninformative prior, because the informative prior mean can be 1 order of magnitude away from the true value, opposed to 2 orders of magnitude for the uninformative prior. However, the prior std deviation is 4 times as small for the informative prior. Also in general the standard deviation is too small, with 95% of uninformative prior density spanning only 2 orders of magnitude. So prior density is quite concentrated in the centre of the bounds, but this may not be realistic with the occurence of hydraulic conductivities in practice. 

% LIKELIHOOD
Using more observations for evaluating the likelihood had a generally negative effect on $\widehat{ESS}$ and $\hat{R}$, but a positive effect on the median as an estimate for the true hydraulic conductivity. These results suggest that using more observations leads to a better estimate of the true posterior at the cost of a longer burn-in time. However, the quality of observations also played an important role. An example of this is the calibration of Model 1 with the wide prior. Here, 5 observations produced the worst median, consistent for all samplers (vs 1 and 3 observations). This implies that there is much to gain from improving measurement quality, considering that the stochastically added noise here is based on random and systematic errors for hydraulic head measurements encountered in the field \citep{rau2019error}. Concerningly, \cite{rau2019error} point out that some measurement techniques have not seen performance improvement in decades and that the pursuit of measurement error reduction in hydrogeology is lacking compared to other fields of science.
% LIKIHOOD NOTES
%Noise amount with respect to head differences of true world; a standard deviation of 0.1m is quite a lot as especially near the edge, where head differences are small. 
%Alternatively, if only taking into account measurement errors due to the operator and selection of dip meter, the measurement error has a standard deviation of approximately 20 mm for the depths of the piezometers in our synthetic case studies (Figure 4 \cite{rau2019error}. 
% is more observations better? = not always, quality is important
    % why do 3 observations suck?
    % also why does Model 1 suck with 5 observations?
    % hypothesis: due to stochasticity 5 outlier observations were drawn that pull the posterior density away from the true parameter value. 
%Also in my experiment I know the true error\_distribution. However, what is realistic to know about the likelihood in the real world? How far off are we? This is big discussion point.

% THE IMPORTANCE OF PARAMETER TRANSFORMATION
% testing runs showed 30k simulations without convergence, when parameters were untransformed. Also, some parts of parameter space, namely very small non-negative numbers were almost impossible to reach, due to parameter bounds at 0. 

% EQUIFINALITY AND PARAMETER UNCERTAINTY
Pairs plots revealed correlations between hydraulic conductivities of the shallowest layers, regardless of the model, suggesting equifinality. For Model 4 hydraulic conductivities of the deeper layers show less sensitivity to the other layers, with roughly spherical joint distributions \citep{gelman2021bayesian}. The presence of equifinality can be argued based on the two shallowest layers in Model 2,3, and 4 showing (nonlinear) negative correlations. Physically, this implies that as the hydraulic conductivity of the shallowest layer decreases, the hydraulic conductivity of the layer below it increases, to ensure the total inflow of the well located in the shallowest layer remains the same. 

The posteriors of the parameters of the shallower layers are concentrated on a smaller part of parameter space, than the parameters of the deeper layers. Providing further evidence that the models are most sensitive to the shallower layers. However, even the posteriors of the shallower layers span approximately two orders of magnitude (see for \hyperref[tab_priors]{\textcolor{blue}{Table }\ref{tab_priors}} for conversion), indicating large uncertainty of parameter estimates. 

As a consequence, the hydraulic heads predicted by the models may contain substantial uncertainty. In follow-up research, it could be interesting to perform Posterior Predictive Checks (PPC). These are a set of tools that compare predictions from the calibrated model to the observed data, by taking draws from the joint posterior distribution \citep{gelman2021bayesian}. % alternatively say that I would have like to perform these PPC's to investigate this uncertainty: I intended to quantify and visualize this uncertainty by applying Posterior Predictive Checks. These are a set of tools that compare predictions from the calibrated model to the observed data, typically by taking draws from the joint posterior distribution \citep{gelman2021bayesian}. Unfortunately, this was scrapped due to time limitations. 

% PARAMETER TRANSFORMATION
Testing runs with untransformed parameters showed poor convergence ($\hat{R}$) and very low acceptance fractions for Model 4 (see \hyperref[trace]{\textcolor{blue}{Appendix }\ref{trace}} for a comprehensive description of these testing runs and their results). One of the main causes for this inefficiency is the wide range of possible hydraulic conductivity values, with e.g. clean sand reporting hydraulic conductivities ranging four orders of magnitude \citep{woessner2020hydrogeologic}. As a consequence, the Ensemble moves used in this study, which are based on interpolation, become inefficient at proposing steps. Additionally, hydraulic conductivity cannot be negative, but it can be very close to 0 for aquitards such as clay. Without parameter transformation these small nonzero values are very hard to reach, as the sampler will often propose values that extend into the negative range, which are physically meaningless and must be rejected. As a consequence, the values close to zero will be undersampled. The applied log-transformation (\hyperref[tab_priors]{\textcolor{blue}{Table }\ref{tab_priors}}) solved these issues. By working in logarithmic space, the algorithm can propose steps that are more appropriate for a parameter that varies over multiple orders of magnitude. This allows the ensemble moves to remain effective, ensuring that proposals remain well-scaled relative to parameter space \citep{sas2020example}. 

Although recommended, it is unclear whether hydrogeologists apply parameter transformation in their studies, often it is not reported \citep{vrugt2009accelerating, laloy2012high}. % documenteer trefwoorden etc waarmee ik dit gecheckt heb.
Furthermore, parameter transformation may be confused with a change of variables: "A transformation samples a parameter, then transforms it, whereas a change of variables transforms a parameter, then samples it". Applying parameter transformation is recommended, because a change of variables requires a Jacobian adjustment \citep{stan_reparameterization}. 

% COMPARISON to Brunetti et al. (2023)
Our results are contrary to the results of \cite{brunetti2023depth}, who recommend the use of AI-based strategies below 10 dimensions and DE-based strategies above that threshold. The one caveat being that \cite{brunetti2023depth} performed vadose zone modelling experiments (Hydrus-1D), versus modelling groundwater flow. 

Diving into the research performed by \cite{brunetti2023depth} reveals that they  recommend AI-based strategies for lower dimensions based on results from a toy distribution and of a synthetic vadose modelling scenario. The toy distribution is a 10-dimensional Rosenbrock distribution, which is banana shaped, as frequently encountered in vadose zone modelling \cite{brunetti2023depth}. In the synthetic scenario the different samplers are used for calibrating 7 soil hydraulic parameters in a Hydrus-1D model, using synthetic observations from a weighable lysimeter.

Regarding the 10-dimensional Rosenbrock distribution, \cite{brunetti2023depth} point out that results show poor convergence for DE and DE-SNK, when using 11 chains, based on the Earth's Movers Distance, which quantifies the cost required to transform the sampled posterior distribution to the true posterior distribution (Rosenbrock). However, this is not how these samplers should be used; Ter Braak recommends always using atleast twice as many chains per ensemble, as there are dimensions. Indeed, when using 20 chains or more, these convergence problems disappear \citep{brunetti2023depth}. %Actually, the integrated autocorrelation time ($\hat{\tau}_f$), which is inversely proportional to the $\widehat{ESS}$ suggests that DE and DE-SNK outperform AI for N=20 when initializing  

For the synthetic scenario, results in \cite{brunetti2023depth} show very low acceptance rates for DE and DE-SNK, opposed to nearly optimal acceptance rates for AI. As a consequence, the integrated autocorrelation time ($\hat{\tau}_f$) is hundreds of steps long for the shown ensembles, which consist of 50, 100 and 200 chains, respectively. %Alarmingly, $\hat{\tau}_f$ increases with step number, while typically $\hat{\tau}_f$ is large during burn-in and decreases once the chains are close to convergence \citep{hogg2018data}.  

\cite{brunetti2023depth} suggest that these low acceptance rates for DE and DE-SNK could be improved by dynamically adapting tuning parameters (the user-defined scalar parameters in \hyperref[fig2]{\textcolor{blue}{Figure }\ref{fig2}} and \hyperref[fig2b]{\textcolor{blue}{Figure }\ref{fig2b}}). However, they do not specify whether parameter transformation was applied. If parameter transformation was not applied, this could explain the low acceptance rates. %, and possibly the discrepancy with our results.

%\cite{brunetti2023depth} used uniform priors and a Gaussian likelihood function with constant variance. 

% UNIMPORTANT REST
% alternatively, I could have also calculated the credible interval of the median (see chapter 7.7 of a Students guide to Bayesian Statistics)

%KDE estimation has the effect of increasing the apparent variance in your uncertainty, due to smoothing. Also tails are rounded due to smoothing, e.g. a uniform distribution gets rounded tails instead of a sharp cut-off. See: https://docs.analytica.com/index.php/Kernel_Density_Smoothing#:~:text=Kernel%20Density%20Smoothing%2C%20also%20known,by%20adding%20up%20these%20Gaussians.

% notation to use for priors and posteriors from now on: prior = \pi(\theta_n), posterior = \p(\theta_n) and mention leaving out |data
% discuss that prior choice influences chain initialisation (the way I modeled it)

%\cite{foreman2013emcee}, the authors from emcee suggest a different method to calculate autocorrelation than \cite{gelman2021bayesian}. Although there seem to be a lot of similarities.